{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/RAG/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/RAG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /teamspace/studios/this_studio/RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_residuals_tensors = torch.load(\"h_residuals_eval.pt\",map_location=torch.device('cpu'))\n",
    "hl_residuals_tensors = torch.load(\"h_residuals_eval.pt\",map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_residuals_tensors),len(hl_residuals_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 4096])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_residuals_tensors[3][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_residuals = [[] for i in range(33)]\n",
    "hl_residuals = [[] for i in range(33)]\n",
    "for i in h_residuals_tensors:\n",
    "    for j in range(33):\n",
    "        for k in i[j].squeeze():\n",
    "            h_residuals[j].append(k)\n",
    "for i in hl_residuals_tensors:\n",
    "    for j in range(33):\n",
    "        for k in i[j].squeeze():\n",
    "            hl_residuals[j].append(k)\n",
    "h_residuals = [torch.stack(i) for i in h_residuals]\n",
    "hl_residuals = [torch.stack(i) for i in hl_residuals]\n",
    "h_residuals_tensor = torch.stack(h_residuals)\n",
    "hl_residuals_tensor = torch.stack(hl_residuals)\n",
    "hl_residuals_tensor = hl_residuals_tensor.squeeze()\n",
    "h_residuals_tensor = h_residuals_tensor.squeeze()\n",
    "\n",
    "hl_residuals_tensor = torch.reshape(hl_residuals_tensor,(33,-1,4096))\n",
    "h_residuals_tensor = torch.reshape(h_residuals_tensor,(33,-1,4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33, 154, 4096]), torch.Size([33, 154, 4096]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_residuals_tensor.shape,hl_residuals_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_residuals_tensor = hl_residuals_tensor[:,:943,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'residuals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m residuals_tensor \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresiduals\u001b[49m:\n\u001b[1;32m      3\u001b[0m     residuals_tensor\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mstack(i))\n\u001b[1;32m      4\u001b[0m h_residuals \u001b[38;5;241m=\u001b[39m residuals_tensor[:\u001b[38;5;241m42\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'residuals' is not defined"
     ]
    }
   ],
   "source": [
    "residuals_tensor = []\n",
    "for i in residuals:\n",
    "    residuals_tensor.append(torch.stack(i))\n",
    "h_residuals = residuals_tensor[:42]\n",
    "hl_residuals = residuals_tensor[42:]\n",
    "h_residuals_tensor = torch.stack(h_residuals)\n",
    "hl_residuals_tensor = torch.stack(hl_residuals)\n",
    "hl_residuals_tensor = hl_residuals_tensor.squeeze()\n",
    "h_residuals_tensor = h_residuals_tensor.squeeze()\n",
    "hl_residuals_tensor = torch.reshape(hl_residuals_tensor,(33,-1,4096))\n",
    "h_residuals_tensor = torch.reshape(h_residuals_tensor,(33,-1,4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 154, 4096])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_residuals_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 4096])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_mean = []\n",
    "hl_mean = []\n",
    "for i in h_residuals_tensor:\n",
    "    h_mean.append(i.mean(0))\n",
    "for i in hl_residuals_tensor:\n",
    "    hl_mean.append(i.mean(0))\n",
    "h_mean = torch.stack(h_mean)\n",
    "hl_mean = torch.stack(hl_mean)\n",
    "h_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(hl_mean,\"hl_mean.pt\")\n",
    "torch.save(h_mean,\"h_mean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_mean = torch.load(\"hl_mean.pt\")\n",
    "h_mean = torch.load(\"h_mean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 4096])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_diff = hl_mean - h_mean\n",
    "mean_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16,\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_residuals_eval_tensors = torch.load(\"h_residuals_eval.pt\",map_location=torch.device('cpu'))\n",
    "hl_residuals_eval_tensors = torch.load(\"hl_residuals_eval.pt\",map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_residuals = [[] for i in range(33)]\n",
    "hl_residuals = [[] for i in range(33)]\n",
    "for i in h_residuals_eval_tensors:\n",
    "    for j in range(33):\n",
    "        for k in i[j].squeeze():\n",
    "            h_residuals[j].append(k)\n",
    "for i in hl_residuals_eval_tensors:\n",
    "    for j in range(33):\n",
    "        for k in i[j].squeeze():\n",
    "            hl_residuals[j].append(k)\n",
    "h_residuals = [torch.stack(i) for i in h_residuals]\n",
    "hl_residuals = [torch.stack(i) for i in hl_residuals]\n",
    "h_residuals_tensor = torch.stack(h_residuals)\n",
    "hl_residuals_tensor = torch.stack(hl_residuals)\n",
    "hl_residuals_tensor = hl_residuals_tensor.squeeze()\n",
    "h_residuals_tensor = h_residuals_tensor.squeeze()\n",
    "\n",
    "hl_residuals_tensor = torch.reshape(hl_residuals_tensor,(33,-1,4096))\n",
    "h_residuals_tensor = torch.reshape(h_residuals_tensor,(33,-1,4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 100, 4096])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_residuals_tensor = h_residuals_tensor[:,:100,:]\n",
    "hl_residuals_tensor = hl_residuals_tensor[:,:100,:]\n",
    "h_residuals_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 200, 4096])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([h_residuals_tensor,hl_residuals_tensor],axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels = torch.stack([*torch.zeros(100),*torch.ones(100)])\n",
    "validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Refusal Direction (Layer): tensor(0)\n",
      "Optimal Refusal Direction Vector: tensor([nan, nan, nan,  ..., nan, nan, nan], dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28719/3156558793.py:11: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  projections = validation_data @ direction.T\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Step 1: Calculate Mean Difference Vectors (Example data)\n",
    "mean_diff_vectors = mean_diff  # Example mean difference vectors\n",
    "\n",
    "# Step 2: Normalize the Mean Difference Vectors\n",
    "normalized_diff_vectors = mean_diff_vectors / mean_diff_vectors.norm(dim=1, keepdim=True)\n",
    "\n",
    "# Step 3: Evaluate Each Normalized Direction\n",
    "def evaluate_direction(direction, validation_data):\n",
    "    projections = validation_data @ direction.T\n",
    "    harmful_projections = projections[validation_labels == 1]\n",
    "    non_harmful_projections = projections[validation_labels == 0]\n",
    "    score = (harmful_projections.mean() - non_harmful_projections.mean()).abs()\n",
    "    return score.item()\n",
    "\n",
    "# Example validation data and labels\n",
    "validation_data = torch.cat([h_residuals_tensor,hl_residuals_tensor],axis=1) # Example validation data\n",
    "validation_labels = torch.stack([*torch.ones(100),*torch.zeros(100)])  # Binary labels (0: non-harmful, 1: harmful)\n",
    "\n",
    "scores = [evaluate_direction(direction, validation_data[i]) for i,direction in enumerate(normalized_diff_vectors)]\n",
    "\n",
    "# Step 4: Select the Best Direction\n",
    "best_direction_index = torch.argmax(torch.tensor(scores))\n",
    "optimal_refusal_direction = normalized_diff_vectors[best_direction_index]\n",
    "\n",
    "print(\"Optimal Refusal Direction (Layer):\", best_direction_index)\n",
    "print(\"Optimal Refusal Direction Vector:\", optimal_refusal_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan,  ..., nan, nan, nan], dtype=torch.float16,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_diff_vectors[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Half",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n\u001b[1;32m      9\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m4096\u001b[39m)  \u001b[38;5;66;03m# Example validation data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m scores \u001b[38;5;241m=\u001b[39m [evaluate_direction(direction, validation_data) \u001b[38;5;28;01mfor\u001b[39;00m direction \u001b[38;5;129;01min\u001b[39;00m normalized_diff_vectors]\n",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n\u001b[1;32m      9\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m4096\u001b[39m)  \u001b[38;5;66;03m# Example validation data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m scores \u001b[38;5;241m=\u001b[39m [\u001b[43mevaluate_direction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m direction \u001b[38;5;129;01min\u001b[39;00m normalized_diff_vectors]\n",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m, in \u001b[0;36mevaluate_direction\u001b[0;34m(direction, validation_data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_direction\u001b[39m(direction, validation_data):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Project validation data onto the direction\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     projections \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Compute some score, e.g., difference in means, classification accuracy, etc.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     score \u001b[38;5;241m=\u001b[39m compute_score(projections)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Half"
     ]
    }
   ],
   "source": [
    "# Assuming you have a function to compute the score for each direction\n",
    "def evaluate_direction(direction, validation_data):\n",
    "    # Project validation data onto the direction\n",
    "    projections = validation_data @ direction.T\n",
    "    # Compute some score, e.g., difference in means, classification accuracy, etc.\n",
    "    score = compute_score(projections)\n",
    "    return score\n",
    "\n",
    "validation_data = torch.randn(100, 4096)  # Example validation data\n",
    "scores = [evaluate_direction(direction, validation_data) for direction in normalized_diff_vectors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0445, -0.0067, -0.0494,  ...,  0.0464,  0.0305, -0.0188],\n",
       "        [ 0.1372,  0.0489, -0.0144,  ...,  0.0309, -0.0786, -0.0573],\n",
       "        [ 0.0542,  0.0238,  0.0421,  ..., -0.0037, -0.0235, -0.0103],\n",
       "        ...,\n",
       "        [ 0.0949,  0.1027, -0.0589,  ...,  0.1155,  0.0649, -0.0217],\n",
       "        [-0.0548, -0.1085,  0.0116,  ...,  0.0891,  0.0804,  0.0151],\n",
       "        [ 0.1182,  0.0590,  0.0128,  ...,  0.0050, -0.0399, -0.0374]],\n",
       "       dtype=torch.float16, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mean_diff,\"mean_diff1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0323, -0.0023, -0.0378,  ...,  0.0029,  0.0023, -0.0116],\n",
       "        [-0.1018,  0.0226, -0.1803,  ...,  0.0419, -0.0576, -0.1185],\n",
       "        [ 0.0278, -0.0320, -0.0507,  ...,  0.0207, -0.0487,  0.0005],\n",
       "        ...,\n",
       "        [-0.0504, -0.0121,  0.0203,  ...,  0.0235, -0.0176, -0.0512],\n",
       "        [-0.0494, -0.0894,  0.0415,  ...,  0.0504, -0.0562,  0.0295],\n",
       "        [ 0.1012, -0.0847, -0.1178,  ..., -0.2128,  0.1364,  0.0286]],\n",
       "       dtype=torch.float16, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_residuals = residuals[:42]\n",
    "hl_residuals = residuals[42:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42*26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmfull_residuals=[]\n",
    "harmless_residuals=[]\n",
    "for i in h_residuals:\n",
    "    for j in i:\n",
    "        for k in j.squeeze():\n",
    "            harmfull_residuals.append(k)\n",
    "for i in hl_residuals:\n",
    "    for j in i:\n",
    "        for k in j.squeeze():\n",
    "            harmless_residuals.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmfull_residuals,harmless_residuals=harmfull_residuals[:len(harmfull_residuals)//2],harmfull_residuals[len(harmfull_residuals)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18018"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(harmfull_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmfull_residuals = torch.stack(harmfull_residuals)\n",
    "harmless_residuals = torch.stack(harmless_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_mean=harmfull_residuals.mean(0)\n",
    "hl_mean=harmless_residuals.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = hl_mean-h_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0138, -0.0013, -0.0062,  ..., -0.0095, -0.0127, -0.0044],\n",
       "       dtype=torch.float16, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mean,\"mean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.load(\"mean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0792, 0.0333, 0.0212,  ..., 0.0326, 0.0004, 0.0040],\n",
       "       dtype=torch.float16, requires_grad=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
